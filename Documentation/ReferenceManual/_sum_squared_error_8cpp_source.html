<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>Flood: SumSquaredError.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.9 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="files.html"><span>File&nbsp;List</span></a></li>
    </ul>
  </div>
<h1>SumSquaredError.cpp</h1><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">/****************************************************************************************************************/</span>
<a name="l00002"></a>00002 <span class="comment">/*                                                                                                              */</span>
<a name="l00003"></a>00003 <span class="comment">/*   Flood: An Open Source Neural Networks C++ Library                                                          */</span>
<a name="l00004"></a>00004 <span class="comment">/*   www.cimne.com/flood                                                                                        */</span>
<a name="l00005"></a>00005 <span class="comment">/*                                                                                                              */</span>
<a name="l00006"></a>00006 <span class="comment">/*   S U M   S Q U A R E D   E R R O R   C L A S S                                                              */</span>
<a name="l00007"></a>00007 <span class="comment">/*                                                                                                              */</span>
<a name="l00008"></a>00008 <span class="comment">/*   Roberto Lopez                                                                                              */</span>
<a name="l00009"></a>00009 <span class="comment">/*   International Center for Numerical Methods in Engineering (CIMNE)                                          */</span>
<a name="l00010"></a>00010 <span class="comment">/*   Technical University of Catalonia (UPC)                                                                    */</span>
<a name="l00011"></a>00011 <span class="comment">/*   Barcelona, Spain                                                                                           */</span>
<a name="l00012"></a>00012 <span class="comment">/*   E-mail: rlopez@cimne.upc.edu                                                                               */</span>
<a name="l00013"></a>00013 <span class="comment">/*                                                                                                              */</span>
<a name="l00014"></a>00014 <span class="comment">/****************************************************************************************************************/</span>
<a name="l00015"></a>00015 
<a name="l00016"></a>00016 <span class="comment">// Flood includes</span>
<a name="l00017"></a>00017 
<a name="l00018"></a>00018 <span class="preprocessor">#include "SumSquaredError.h"</span>
<a name="l00019"></a>00019 
<a name="l00020"></a>00020 <span class="comment">// System includes</span>
<a name="l00021"></a>00021 
<a name="l00022"></a>00022 <span class="preprocessor">#include &lt;string&gt;</span>
<a name="l00023"></a>00023 <span class="preprocessor">#include &lt;sstream&gt;</span>
<a name="l00024"></a>00024 <span class="preprocessor">#include &lt;iostream&gt;</span>
<a name="l00025"></a>00025 <span class="preprocessor">#include &lt;fstream&gt;</span>
<a name="l00026"></a>00026 <span class="preprocessor">#include &lt;cmath&gt;</span>
<a name="l00027"></a>00027 
<a name="l00028"></a>00028 <span class="keyword">namespace </span>Flood
<a name="l00029"></a>00029 {
<a name="l00030"></a>00030 
<a name="l00031"></a>00031 <span class="comment">// DEFAULT CONSTRUCTOR</span>
<a name="l00032"></a>00032 
<a name="l00036"></a>00036 
<a name="l00037"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#eae157f224e6d41474f149ec235f540c">00037</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#eae157f224e6d41474f149ec235f540c">SumSquaredError::SumSquaredError</a>(<span class="keywordtype">void</span>) : <a class="code" href="class_flood_1_1_objective_functional.html">ObjectiveFunctional</a>()
<a name="l00038"></a>00038 {
<a name="l00039"></a>00039    input_target_data_set_pointer = NULL;
<a name="l00040"></a>00040 }
<a name="l00041"></a>00041 
<a name="l00042"></a>00042 
<a name="l00043"></a>00043 <span class="comment">// MULTILAYER PERCEPTRON CONSTRUCTOR</span>
<a name="l00044"></a>00044 
<a name="l00049"></a>00049 
<a name="l00050"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#631d999cb2ee1a876bd739869f11b494">00050</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#eae157f224e6d41474f149ec235f540c">SumSquaredError::SumSquaredError</a>(<a class="code" href="class_flood_1_1_multilayer_perceptron.html" title="This class represents the concept of multilayer perceptron neural network.">MultilayerPerceptron</a>* new_multilayer_perceptron_pointer) 
<a name="l00051"></a>00051 : <a class="code" href="class_flood_1_1_objective_functional.html">ObjectiveFunctional</a>(new_multilayer_perceptron_pointer)
<a name="l00052"></a>00052 {
<a name="l00053"></a>00053    input_target_data_set_pointer = NULL;
<a name="l00054"></a>00054 }
<a name="l00055"></a>00055 
<a name="l00056"></a>00056 
<a name="l00057"></a>00057 <span class="comment">// INPUT-TARGET DATA SET CONSTRUCTOR</span>
<a name="l00058"></a>00058 
<a name="l00063"></a>00063 
<a name="l00064"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#515b9245920d6e9f4e2885fbfeff2c93">00064</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#eae157f224e6d41474f149ec235f540c">SumSquaredError::SumSquaredError</a>(<a class="code" href="class_flood_1_1_input_target_data_set.html">InputTargetDataSet</a>* new_input_target_data_set_pointer)
<a name="l00065"></a>00065 : <a class="code" href="class_flood_1_1_objective_functional.html">ObjectiveFunctional</a>()
<a name="l00066"></a>00066 {
<a name="l00067"></a>00067    input_target_data_set_pointer = new_input_target_data_set_pointer;
<a name="l00068"></a>00068 }
<a name="l00069"></a>00069 
<a name="l00070"></a>00070 
<a name="l00071"></a>00071 <span class="comment">// GENERAL CONSTRUCTOR</span>
<a name="l00072"></a>00072 
<a name="l00078"></a>00078 
<a name="l00079"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#612a05a884bca5ea0bef956b4a886c3d">00079</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#eae157f224e6d41474f149ec235f540c">SumSquaredError::SumSquaredError</a>(<a class="code" href="class_flood_1_1_multilayer_perceptron.html" title="This class represents the concept of multilayer perceptron neural network.">MultilayerPerceptron</a>* new_multilayer_perceptron_pointer, 
<a name="l00080"></a>00080 <a class="code" href="class_flood_1_1_input_target_data_set.html">InputTargetDataSet</a>* new_input_target_data_set_pointer): <a class="code" href="class_flood_1_1_objective_functional.html">ObjectiveFunctional</a>(new_multilayer_perceptron_pointer)
<a name="l00081"></a>00081 {
<a name="l00082"></a>00082    input_target_data_set_pointer = new_input_target_data_set_pointer;
<a name="l00083"></a>00083 }
<a name="l00084"></a>00084 
<a name="l00085"></a>00085 
<a name="l00086"></a>00086 <span class="comment">// DESTRUCTOR</span>
<a name="l00087"></a>00087 
<a name="l00089"></a>00089 
<a name="l00090"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#0a3e375036d47780a18587bd26915ea5">00090</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#0a3e375036d47780a18587bd26915ea5" title="Destructor.">SumSquaredError::~SumSquaredError</a>(<span class="keywordtype">void</span>) 
<a name="l00091"></a>00091 {
<a name="l00092"></a>00092 }
<a name="l00093"></a>00093 
<a name="l00094"></a>00094 
<a name="l00095"></a>00095 <span class="comment">// METHODS</span>
<a name="l00096"></a>00096 
<a name="l00097"></a>00097 
<a name="l00098"></a>00098 <span class="comment">// void set(void) method</span>
<a name="l00099"></a>00099 
<a name="l00102"></a>00102 
<a name="l00103"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#4a96e5e1294050c8f93d1878ef668a0f">00103</a> <span class="keywordtype">void</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#4a96e5e1294050c8f93d1878ef668a0f">SumSquaredError::set</a>(<span class="keywordtype">void</span>)
<a name="l00104"></a>00104 {
<a name="l00105"></a>00105    <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> = NULL;
<a name="l00106"></a>00106    input_target_data_set_pointer = NULL;
<a name="l00107"></a>00107    <a class="code" href="class_flood_1_1_objective_functional.html#128b310e5949469810f44b4eaad172e3">set_default</a>();
<a name="l00108"></a>00108 }
<a name="l00109"></a>00109 
<a name="l00110"></a>00110 
<a name="l00111"></a>00111 <span class="comment">// void set(MultilayerPerceptron*) method</span>
<a name="l00112"></a>00112 
<a name="l00116"></a>00116 
<a name="l00117"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#cc270898ce0c36c569d9ebe55e16883b">00117</a> <span class="keywordtype">void</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#4a96e5e1294050c8f93d1878ef668a0f">SumSquaredError::set</a>(<a class="code" href="class_flood_1_1_multilayer_perceptron.html" title="This class represents the concept of multilayer perceptron neural network.">MultilayerPerceptron</a>* new_multilayer_perceptron_pointer)
<a name="l00118"></a>00118 {
<a name="l00119"></a>00119    <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> = new_multilayer_perceptron_pointer;
<a name="l00120"></a>00120    input_target_data_set_pointer = NULL;
<a name="l00121"></a>00121    <a class="code" href="class_flood_1_1_objective_functional.html#128b310e5949469810f44b4eaad172e3">set_default</a>();
<a name="l00122"></a>00122 }
<a name="l00123"></a>00123 
<a name="l00124"></a>00124 
<a name="l00125"></a>00125 <span class="comment">// void set(InputTargetDataSet*) method</span>
<a name="l00126"></a>00126 
<a name="l00130"></a>00130 
<a name="l00131"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#957aab1fec9db7f7b5fdd6a0ec258dfd">00131</a> <span class="keywordtype">void</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#4a96e5e1294050c8f93d1878ef668a0f">SumSquaredError::set</a>(<a class="code" href="class_flood_1_1_input_target_data_set.html">InputTargetDataSet</a>* new_input_target_data_set_pointer)
<a name="l00132"></a>00132 {
<a name="l00133"></a>00133    <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> = NULL;
<a name="l00134"></a>00134    input_target_data_set_pointer = new_input_target_data_set_pointer;
<a name="l00135"></a>00135    <a class="code" href="class_flood_1_1_objective_functional.html#128b310e5949469810f44b4eaad172e3">set_default</a>();
<a name="l00136"></a>00136 }
<a name="l00137"></a>00137 
<a name="l00138"></a>00138 
<a name="l00139"></a>00139 <span class="comment">// void set(MultilayerPerceptron*, InputTargetDataSet*) method</span>
<a name="l00140"></a>00140 
<a name="l00145"></a>00145 
<a name="l00146"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#d7a361b61c2918725c6921a8d83a8236">00146</a> <span class="keywordtype">void</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#4a96e5e1294050c8f93d1878ef668a0f">SumSquaredError::set</a>(<a class="code" href="class_flood_1_1_multilayer_perceptron.html" title="This class represents the concept of multilayer perceptron neural network.">MultilayerPerceptron</a>* new_multilayer_perceptron_pointer, <a class="code" href="class_flood_1_1_input_target_data_set.html">InputTargetDataSet</a>* new_input_target_data_set_pointer)
<a name="l00147"></a>00147 {
<a name="l00148"></a>00148    <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> = new_multilayer_perceptron_pointer;
<a name="l00149"></a>00149    input_target_data_set_pointer = new_input_target_data_set_pointer;
<a name="l00150"></a>00150    <a class="code" href="class_flood_1_1_objective_functional.html#128b310e5949469810f44b4eaad172e3">set_default</a>();
<a name="l00151"></a>00151 }
<a name="l00152"></a>00152 
<a name="l00153"></a>00153 
<a name="l00154"></a>00154 <span class="comment">// void set_input_target_data_set_pointer(InputTargetDataSet*) method</span>
<a name="l00155"></a>00155 
<a name="l00158"></a>00158 
<a name="l00159"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#48d02c6c313a14cf1b187ac911b37953">00159</a> <span class="keywordtype">void</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#48d02c6c313a14cf1b187ac911b37953">SumSquaredError::set_input_target_data_set_pointer</a>(<a class="code" href="class_flood_1_1_input_target_data_set.html">InputTargetDataSet</a>* new_input_target_data_set_pointer)
<a name="l00160"></a>00160 {
<a name="l00161"></a>00161    input_target_data_set_pointer = new_input_target_data_set_pointer;
<a name="l00162"></a>00162 }
<a name="l00163"></a>00163 
<a name="l00164"></a>00164 
<a name="l00165"></a>00165 <span class="comment">// double calculate_objective(void) method</span>
<a name="l00166"></a>00166 
<a name="l00169"></a>00169 
<a name="l00170"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#e9acf44fcb70ac259ca00611dc37b9c5">00170</a> <span class="keywordtype">double</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#e9acf44fcb70ac259ca00611dc37b9c5">SumSquaredError::calculate_objective</a>(<span class="keywordtype">void</span>)
<a name="l00171"></a>00171 {
<a name="l00172"></a>00172    <span class="comment">// Control sentence (if debug)</span>
<a name="l00173"></a>00173 
<a name="l00174"></a>00174 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00175"></a>00175 <span class="preprocessor"></span>
<a name="l00176"></a>00176    <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> == NULL)
<a name="l00177"></a>00177    {
<a name="l00178"></a>00178       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00179"></a>00179                 &lt;&lt; <span class="stringliteral">"double calculate_objective(void) method."</span> &lt;&lt; std::endl
<a name="l00180"></a>00180                 &lt;&lt; <span class="stringliteral">"Pointer to multilayer perceptron object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l00181"></a>00181 
<a name="l00182"></a>00182         exit(1);
<a name="l00183"></a>00183    }
<a name="l00184"></a>00184    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(input_target_data_set_pointer == NULL)
<a name="l00185"></a>00185    {
<a name="l00186"></a>00186       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00187"></a>00187                 &lt;&lt; <span class="stringliteral">"double calculate_objective(void) method."</span> &lt;&lt; std::endl
<a name="l00188"></a>00188                 &lt;&lt; <span class="stringliteral">"Pointer to input-target data set object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l00189"></a>00189 
<a name="l00190"></a>00190       exit(1);
<a name="l00191"></a>00191    }
<a name="l00192"></a>00192 
<a name="l00193"></a>00193 <span class="preprocessor">   #endif</span>
<a name="l00194"></a>00194 <span class="preprocessor"></span>
<a name="l00195"></a>00195    <span class="keywordtype">int</span> training_instances_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#57033471aae443333b57a24ebbf4910e" title="This method returns the number of instances in the data set which will be used for...">get_training_instances_number</a>();
<a name="l00196"></a>00196 
<a name="l00197"></a>00197    <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f6eca87cfe21b50fe1018152fa696788" title="This method returns the number of inputs in the neural network.">get_inputs_number</a>();
<a name="l00198"></a>00198    <span class="keywordtype">int</span> outputs_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#eb935150e692d7782823128c788fad9c" title="This method returns the number of neurons in the output layer of the neural network...">get_outputs_number</a>();
<a name="l00199"></a>00199 
<a name="l00200"></a>00200 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00201"></a>00201 <span class="preprocessor"></span>
<a name="l00202"></a>00202    <span class="keywordtype">int</span> input_variables_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#912c95fd2c5a33390771adfa4c835960" title="This method returns the number of input variables of the input-target data set.">get_input_variables_number</a>();
<a name="l00203"></a>00203 
<a name="l00204"></a>00204    <span class="keywordflow">if</span>(inputs_number != input_variables_number)
<a name="l00205"></a>00205    {
<a name="l00206"></a>00206       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00207"></a>00207                 &lt;&lt; <span class="stringliteral">"double calculate_objective(void) method."</span> &lt;&lt; std::endl
<a name="l00208"></a>00208                 &lt;&lt; <span class="stringliteral">"Number of inputs in multilayer perceptron must be equal to "</span> 
<a name="l00209"></a>00209                 &lt;&lt; <span class="stringliteral">"number of input variables in input-target data set."</span> &lt;&lt; std::endl;
<a name="l00210"></a>00210 
<a name="l00211"></a>00211       exit(1);
<a name="l00212"></a>00212    }
<a name="l00213"></a>00213 
<a name="l00214"></a>00214    <span class="keywordtype">int</span> target_variables_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#7617eae51cdb86c8fefb8c5a608962ed" title="This method returns the number of target variables of the input-target data set.">get_target_variables_number</a>();
<a name="l00215"></a>00215 
<a name="l00216"></a>00216    <span class="keywordflow">if</span>(outputs_number != target_variables_number)
<a name="l00217"></a>00217    {
<a name="l00218"></a>00218       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00219"></a>00219                 &lt;&lt; <span class="stringliteral">"double calculate_objective(void) method."</span> &lt;&lt; std::endl
<a name="l00220"></a>00220                 &lt;&lt; <span class="stringliteral">"Number of outputs in multilayer perceptron must be equal to "</span> 
<a name="l00221"></a>00221                 &lt;&lt; <span class="stringliteral">"number of target variables in input-target data set."</span> &lt;&lt; std::endl;
<a name="l00222"></a>00222 
<a name="l00223"></a>00223       exit(1);
<a name="l00224"></a>00224    }
<a name="l00225"></a>00225 
<a name="l00226"></a>00226 <span class="preprocessor">   #endif</span>
<a name="l00227"></a>00227 <span class="preprocessor"></span>
<a name="l00228"></a>00228    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> input(inputs_number);
<a name="l00229"></a>00229    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output(outputs_number);
<a name="l00230"></a>00230    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> target(outputs_number);
<a name="l00231"></a>00231    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> instance_error(outputs_number);
<a name="l00232"></a>00232 
<a name="l00233"></a>00233    <span class="keywordtype">double</span> training_error = 0.0;
<a name="l00234"></a>00234 
<a name="l00235"></a>00235    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; training_instances_number; i++)
<a name="l00236"></a>00236    {
<a name="l00237"></a>00237       <span class="comment">// Input vector</span>
<a name="l00238"></a>00238 
<a name="l00239"></a>00239           input = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#51b4afaebebd097d321d3f3bed696093">get_training_input_instance</a>(i);
<a name="l00240"></a>00240 
<a name="l00241"></a>00241       <span class="comment">// Output vector</span>
<a name="l00242"></a>00242 
<a name="l00243"></a>00243       output = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#174c73e190ed9f64f4e56cb697f8cdd8">calculate_output</a>(input);
<a name="l00244"></a>00244 
<a name="l00245"></a>00245       <span class="comment">// Target vector</span>
<a name="l00246"></a>00246 
<a name="l00247"></a>00247       target = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#61497ffefa06bc839723af12fd1342f1">get_training_target_instance</a>(i);
<a name="l00248"></a>00248 
<a name="l00249"></a>00249       <span class="comment">// Error</span>
<a name="l00250"></a>00250 
<a name="l00251"></a>00251            instance_error = output - target;
<a name="l00252"></a>00252 
<a name="l00253"></a>00253       <span class="comment">// Sum of squares error</span>
<a name="l00254"></a>00254 
<a name="l00255"></a>00255       training_error += instance_error.<a class="code" href="class_flood_1_1_vector.html#4edb8686026ca9b62e6dad5c68fc5738">dot</a>(instance_error);           
<a name="l00256"></a>00256    }
<a name="l00257"></a>00257 
<a name="l00258"></a>00258    <span class="keywordflow">return</span>(training_error);
<a name="l00259"></a>00259 }
<a name="l00260"></a>00260 
<a name="l00261"></a>00261 
<a name="l00262"></a>00262 <span class="comment">// double calculate_validation_error(void) method</span>
<a name="l00263"></a>00263 
<a name="l00266"></a>00266 
<a name="l00267"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#54c9586ed180affdbf53ab8b2a607b1b">00267</a> <span class="keywordtype">double</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#54c9586ed180affdbf53ab8b2a607b1b">SumSquaredError::calculate_validation_error</a>(<span class="keywordtype">void</span>)
<a name="l00268"></a>00268 {
<a name="l00269"></a>00269    <span class="comment">// Control sentence (if debug)</span>
<a name="l00270"></a>00270 
<a name="l00271"></a>00271 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00272"></a>00272 <span class="preprocessor"></span>
<a name="l00273"></a>00273    <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> == NULL)
<a name="l00274"></a>00274    {
<a name="l00275"></a>00275       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00276"></a>00276                 &lt;&lt; <span class="stringliteral">"double calculate_validation_error(void) method."</span> &lt;&lt; std::endl
<a name="l00277"></a>00277                 &lt;&lt; <span class="stringliteral">"Pointer to multilayer perceptron object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l00278"></a>00278 
<a name="l00279"></a>00279         exit(1);
<a name="l00280"></a>00280    }
<a name="l00281"></a>00281    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(input_target_data_set_pointer == NULL)
<a name="l00282"></a>00282    {
<a name="l00283"></a>00283       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00284"></a>00284                 &lt;&lt; <span class="stringliteral">"double calculate_validation_error(void) method."</span> &lt;&lt; std::endl
<a name="l00285"></a>00285                 &lt;&lt; <span class="stringliteral">"Pointer to input-target data set object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l00286"></a>00286 
<a name="l00287"></a>00287       exit(1);
<a name="l00288"></a>00288    }
<a name="l00289"></a>00289 
<a name="l00290"></a>00290 <span class="preprocessor">   #endif</span>
<a name="l00291"></a>00291 <span class="preprocessor"></span>
<a name="l00292"></a>00292    <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f6eca87cfe21b50fe1018152fa696788" title="This method returns the number of inputs in the neural network.">get_inputs_number</a>();
<a name="l00293"></a>00293    <span class="keywordtype">int</span> outputs_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#eb935150e692d7782823128c788fad9c" title="This method returns the number of neurons in the output layer of the neural network...">get_outputs_number</a>();
<a name="l00294"></a>00294 
<a name="l00295"></a>00295 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00296"></a>00296 <span class="preprocessor"></span>
<a name="l00297"></a>00297    <span class="keywordtype">int</span> input_variables_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#912c95fd2c5a33390771adfa4c835960" title="This method returns the number of input variables of the input-target data set.">get_input_variables_number</a>();
<a name="l00298"></a>00298    <span class="keywordtype">int</span> target_variables_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#7617eae51cdb86c8fefb8c5a608962ed" title="This method returns the number of target variables of the input-target data set.">get_target_variables_number</a>();
<a name="l00299"></a>00299 
<a name="l00300"></a>00300    <span class="keywordflow">if</span>(inputs_number != input_variables_number || outputs_number != target_variables_number)
<a name="l00301"></a>00301    {
<a name="l00302"></a>00302       std::cout &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00303"></a>00303                 &lt;&lt; <span class="stringliteral">"double calculate_validation_error(void) method."</span> &lt;&lt; std::endl
<a name="l00304"></a>00304                 &lt;&lt; <span class="stringliteral">"Number of inputs and outputs in multilayer perceptron must be equal to "</span> 
<a name="l00305"></a>00305                 &lt;&lt; <span class="stringliteral">"number of input and output variables in input-target data set."</span> &lt;&lt; std::endl;
<a name="l00306"></a>00306 
<a name="l00307"></a>00307       exit(1);
<a name="l00308"></a>00308    }
<a name="l00309"></a>00309 
<a name="l00310"></a>00310 <span class="preprocessor">   #endif</span>
<a name="l00311"></a>00311 <span class="preprocessor"></span>
<a name="l00312"></a>00312    <span class="keywordtype">int</span> validation_instances_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#a8d85b985599564730991d41b1960b21" title="This method returns the number of instances in the data set which will be used for...">get_validation_instances_number</a>();
<a name="l00313"></a>00313 
<a name="l00314"></a>00314    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> input(inputs_number);
<a name="l00315"></a>00315    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output(outputs_number);
<a name="l00316"></a>00316    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> target(outputs_number);
<a name="l00317"></a>00317 
<a name="l00318"></a>00318    <span class="keywordtype">double</span> validation_error = 0.0;
<a name="l00319"></a>00319 
<a name="l00320"></a>00320    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; validation_instances_number; i++)
<a name="l00321"></a>00321    {
<a name="l00322"></a>00322       <span class="comment">// Input vector</span>
<a name="l00323"></a>00323 
<a name="l00324"></a>00324           input = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#df9c8e19f90591903416b2449b7ce957">get_validation_input_instance</a>(i);
<a name="l00325"></a>00325 
<a name="l00326"></a>00326       <span class="comment">// Output vector</span>
<a name="l00327"></a>00327 
<a name="l00328"></a>00328       output = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#174c73e190ed9f64f4e56cb697f8cdd8">calculate_output</a>(input);
<a name="l00329"></a>00329 
<a name="l00330"></a>00330       <span class="comment">// Target vector</span>
<a name="l00331"></a>00331 
<a name="l00332"></a>00332       target = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#98c1faa518e1d189a0184bbaedc20f15">get_validation_target_instance</a>(i);
<a name="l00333"></a>00333 
<a name="l00334"></a>00334       <span class="comment">// Sum of squares error</span>
<a name="l00335"></a>00335 
<a name="l00336"></a>00336       validation_error += (output - target).dot(output - target);           
<a name="l00337"></a>00337    }
<a name="l00338"></a>00338 
<a name="l00339"></a>00339    <span class="keywordflow">return</span>(validation_error);
<a name="l00340"></a>00340 }
<a name="l00341"></a>00341 
<a name="l00342"></a>00342 
<a name="l00343"></a>00343 <span class="comment">// Vector&lt;double&gt; calculate_objective_gradient(void) method</span>
<a name="l00344"></a>00344 
<a name="l00347"></a>00347 
<a name="l00348"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#c0df94419043e8bd9e96b910d70db109">00348</a> <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#c0df94419043e8bd9e96b910d70db109">SumSquaredError::calculate_objective_gradient</a>(<span class="keywordtype">void</span>)
<a name="l00349"></a>00349 {
<a name="l00350"></a>00350    <span class="comment">// Control sentence (if debug)</span>
<a name="l00351"></a>00351 
<a name="l00352"></a>00352 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00353"></a>00353 <span class="preprocessor"></span>
<a name="l00354"></a>00354    <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> == NULL)
<a name="l00355"></a>00355    {
<a name="l00356"></a>00356       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00357"></a>00357                 &lt;&lt; <span class="stringliteral">"double calculate_objective_gradient(void) method."</span> &lt;&lt; std::endl
<a name="l00358"></a>00358                 &lt;&lt; <span class="stringliteral">"Pointer to multilayer perceptron object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l00359"></a>00359 
<a name="l00360"></a>00360         exit(1);
<a name="l00361"></a>00361    }
<a name="l00362"></a>00362    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(input_target_data_set_pointer == NULL)
<a name="l00363"></a>00363    {
<a name="l00364"></a>00364       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00365"></a>00365                 &lt;&lt; <span class="stringliteral">"double calculate_objective_gradient(void) method."</span> &lt;&lt; std::endl
<a name="l00366"></a>00366                 &lt;&lt; <span class="stringliteral">"Pointer to input-target data set object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l00367"></a>00367 
<a name="l00368"></a>00368       exit(1);
<a name="l00369"></a>00369    }
<a name="l00370"></a>00370 
<a name="l00371"></a>00371 <span class="preprocessor">   #endif</span>
<a name="l00372"></a>00372 <span class="preprocessor"></span>
<a name="l00373"></a>00373    <span class="comment">// Multilayer perceptron </span>
<a name="l00374"></a>00374 
<a name="l00375"></a>00375    <span class="keywordtype">int</span> hidden_layers_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#93fca24946b4bb32aca35a2fc3c6169a" title="This method returns the number of hidden layers in the multilayer perceptron.">get_hidden_layers_number</a>();
<a name="l00376"></a>00376 
<a name="l00377"></a>00377    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;int&gt;</a> hidden_layers_size = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#fd29554ea06a09fc3a55a9aef8bab4ca" title="This method returns a vector containing the numbers of neurons in each hidden layer...">get_hidden_layers_size</a>();
<a name="l00378"></a>00378 
<a name="l00379"></a>00379    <span class="keywordtype">int</span> outputs_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#eb935150e692d7782823128c788fad9c" title="This method returns the number of neurons in the output layer of the neural network...">get_outputs_number</a>();
<a name="l00380"></a>00380 
<a name="l00381"></a>00381    <span class="keywordtype">int</span> forward_propagation_derivative_size = 2*hidden_layers_number + 2;
<a name="l00382"></a>00382 
<a name="l00383"></a>00383    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; forward_propagation_derivative(forward_propagation_derivative_size);
<a name="l00384"></a>00384 
<a name="l00385"></a>00385    <span class="comment">// Input-target data set</span>
<a name="l00386"></a>00386 
<a name="l00387"></a>00387    <span class="keywordtype">int</span> training_instances_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#57033471aae443333b57a24ebbf4910e" title="This method returns the number of instances in the data set which will be used for...">get_training_instances_number</a>();
<a name="l00388"></a>00388 
<a name="l00389"></a>00389    <span class="keywordtype">int</span> input_variables_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#912c95fd2c5a33390771adfa4c835960" title="This method returns the number of input variables of the input-target data set.">get_input_variables_number</a>();
<a name="l00390"></a>00390    <span class="keywordtype">int</span> target_variables_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#7617eae51cdb86c8fefb8c5a608962ed" title="This method returns the number of target variables of the input-target data set.">get_target_variables_number</a>();    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> training_input_instance(input_variables_number);
<a name="l00391"></a>00391    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> training_target_instance(target_variables_number);
<a name="l00392"></a>00392 
<a name="l00393"></a>00393    <span class="comment">// Output and hidden errors</span>
<a name="l00394"></a>00394 
<a name="l00395"></a>00395    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output_errors(outputs_number);
<a name="l00396"></a>00396    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; hidden_errors(hidden_layers_number);
<a name="l00397"></a>00397 
<a name="l00398"></a>00398    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = 0; h &lt; hidden_layers_number; h++)
<a name="l00399"></a>00399    {
<a name="l00400"></a>00400       hidden_errors[h].<a class="code" href="class_flood_1_1_vector.html#68039fc58f09f77466d22c5f2c131b02">set_size</a>(hidden_layers_size[h]);
<a name="l00401"></a>00401    }
<a name="l00402"></a>00402 
<a name="l00403"></a>00403    <span class="comment">// Hidden and output layers gradients</span>
<a name="l00404"></a>00404 
<a name="l00405"></a>00405    <span class="keywordtype">int</span> hidden_layers_parameters_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#4ce80b9945c8629c6c5123a69f20e439" title="This method returns the number of neural parameters (biases and synaptic weights)...">get_hidden_layers_parameters_number</a>();
<a name="l00406"></a>00406    <span class="keywordtype">int</span> output_layer_parameters_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#56abb33a0ce8499a33bdf7777f2b93c1" title="This method returns the number of neural parameters (biases and synaptic weights)...">get_output_layer_parameters_number</a>();
<a name="l00407"></a>00407 
<a name="l00408"></a>00408    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> hidden_layers_error_gradient(hidden_layers_parameters_number, 0.0);
<a name="l00409"></a>00409    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output_layer_error_gradient(output_layer_parameters_number, 0.0);
<a name="l00410"></a>00410 
<a name="l00411"></a>00411    <span class="comment">// Main loop</span>
<a name="l00412"></a>00412 
<a name="l00413"></a>00413    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; training_instances_number; i++)
<a name="l00414"></a>00414    {
<a name="l00415"></a>00415       training_input_instance = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#51b4afaebebd097d321d3f3bed696093">get_training_input_instance</a>(i);
<a name="l00416"></a>00416 
<a name="l00417"></a>00417       forward_propagation_derivative = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#94edc7c4a12eec9b777acfee548f4782">calculate_forward_propagation_derivative</a>(training_input_instance);
<a name="l00418"></a>00418 
<a name="l00419"></a>00419       training_target_instance = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#61497ffefa06bc839723af12fd1342f1">get_training_target_instance</a>(i);
<a name="l00420"></a>00420 
<a name="l00421"></a>00421           output_errors = <a class="code" href="class_flood_1_1_sum_squared_error.html#1b89f88d8c08d06b7cb82bc883d2e110">calculate_output_errors</a>(forward_propagation_derivative, training_target_instance);
<a name="l00422"></a>00422 
<a name="l00423"></a>00423       hidden_errors = <a class="code" href="class_flood_1_1_sum_squared_error.html#ead89dbd1ec4e2d8fabb546f7b4f3c1f">calculate_hidden_errors</a>(forward_propagation_derivative, output_errors);
<a name="l00424"></a>00424 
<a name="l00425"></a>00425       hidden_layers_error_gradient += <a class="code" href="class_flood_1_1_sum_squared_error.html#0377f1256a757d4fe942a13313c7decf">calculate_hidden_layers_error_gradient</a>(training_input_instance, forward_propagation_derivative, hidden_errors);
<a name="l00426"></a>00426   
<a name="l00427"></a>00427       output_layer_error_gradient += <a class="code" href="class_flood_1_1_sum_squared_error.html#2785b64fbe0829fe69c263fbf958ffcd">calculate_output_layer_error_gradient</a>(forward_propagation_derivative, output_errors);
<a name="l00428"></a>00428    }
<a name="l00429"></a>00429 
<a name="l00430"></a>00430    <span class="keywordflow">return</span>(hidden_layers_error_gradient.<a class="code" href="class_flood_1_1_vector.html#661629167de2ffe623c451339cb6b11c">assemble</a>(output_layer_error_gradient));   
<a name="l00431"></a>00431 }
<a name="l00432"></a>00432 
<a name="l00433"></a>00433 
<a name="l00434"></a>00434 <span class="comment">// Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method</span>
<a name="l00435"></a>00435 
<a name="l00439"></a>00439 
<a name="l00440"></a>00440 <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#1b89f88d8c08d06b7cb82bc883d2e110">SumSquaredError::calculate_output_errors</a>
<a name="l00441"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#1b89f88d8c08d06b7cb82bc883d2e110">00441</a> (<span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; forward_propagation_derivative, <span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a>&amp; target)
<a name="l00442"></a>00442 {
<a name="l00443"></a>00443    <span class="keywordtype">int</span> forward_propagation_derivative_size = forward_propagation_derivative.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00444"></a>00444    <span class="keywordtype">int</span> outputs_number = multilayer_perceptron_pointer-&gt;get_outputs_number();
<a name="l00445"></a>00445 
<a name="l00446"></a>00446    <span class="comment">// Control sentence (if debug)</span>
<a name="l00447"></a>00447 
<a name="l00448"></a>00448 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00449"></a>00449 <span class="preprocessor"></span>
<a name="l00450"></a>00450    <span class="keywordtype">int</span> hidden_layers_number = multilayer_perceptron_pointer-&gt;get_hidden_layers_number();
<a name="l00451"></a>00451 
<a name="l00452"></a>00452    <span class="keywordflow">if</span>(forward_propagation_derivative_size != 2*hidden_layers_number+2)
<a name="l00453"></a>00453    {
<a name="l00454"></a>00454       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00455"></a>00455                 &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00456"></a>00456                 &lt;&lt; <span class="stringliteral">"Size of forward propagation derivative vector must be equal to 2*hidden_layers_number+2."</span> 
<a name="l00457"></a>00457                                 &lt;&lt; std::endl;
<a name="l00458"></a>00458 
<a name="l00459"></a>00459         exit(1);
<a name="l00460"></a>00460    }
<a name="l00461"></a>00461       
<a name="l00462"></a>00462    <span class="keywordtype">int</span> output_layer_output_size = forward_propagation_derivative[forward_propagation_derivative_size-2].get_size();
<a name="l00463"></a>00463       
<a name="l00464"></a>00464    <span class="keywordflow">if</span>(output_layer_output_size != outputs_number)
<a name="l00465"></a>00465    {
<a name="l00466"></a>00466       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00467"></a>00467                 &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00468"></a>00468                 &lt;&lt; <span class="stringliteral">"Size of output layer output ("</span>&lt;&lt; output_layer_output_size &lt;&lt; <span class="stringliteral">") must be equal to "</span>
<a name="l00469"></a>00469                 &lt;&lt; <span class="stringliteral">"number of outputs ("</span> &lt;&lt; outputs_number &lt;&lt; <span class="stringliteral">")."</span> &lt;&lt; std::endl;
<a name="l00470"></a>00470 
<a name="l00471"></a>00471       exit(1);
<a name="l00472"></a>00472    }
<a name="l00473"></a>00473 
<a name="l00474"></a>00474    <span class="keywordtype">int</span> output_layer_output_derivative_size 
<a name="l00475"></a>00475    = forward_propagation_derivative[forward_propagation_derivative_size-1].get_size();
<a name="l00476"></a>00476 
<a name="l00477"></a>00477    <span class="keywordflow">if</span>(output_layer_output_derivative_size != outputs_number)
<a name="l00478"></a>00478    {
<a name="l00479"></a>00479       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00480"></a>00480                 &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00481"></a>00481                 &lt;&lt; <span class="stringliteral">"Size of output layer output derivative ("</span> &lt;&lt; output_layer_output_derivative_size &lt;&lt; <span class="stringliteral">")must be equal to "</span>               &lt;&lt; <span class="stringliteral">"number of outputs ("</span> &lt;&lt; outputs_number &lt;&lt; <span class="stringliteral">")."</span> &lt;&lt; std::endl;
<a name="l00482"></a>00482 
<a name="l00483"></a>00483       exit(1);
<a name="l00484"></a>00484    }
<a name="l00485"></a>00485 
<a name="l00486"></a>00486    <span class="keywordtype">int</span> target_size = target.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00487"></a>00487 
<a name="l00488"></a>00488    <span class="keywordflow">if</span>(target_size != outputs_number)
<a name="l00489"></a>00489    {
<a name="l00490"></a>00490       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00491"></a>00491                 &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00492"></a>00492                 &lt;&lt; <span class="stringliteral">"Size of target must be equal to number of outputs."</span> &lt;&lt; std::endl;
<a name="l00493"></a>00493 
<a name="l00494"></a>00494       exit(1);
<a name="l00495"></a>00495    }
<a name="l00496"></a>00496 
<a name="l00497"></a>00497 <span class="preprocessor">   #endif</span>
<a name="l00498"></a>00498 <span class="preprocessor"></span>
<a name="l00499"></a>00499    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output_layer_output_derivative = forward_propagation_derivative[forward_propagation_derivative_size-1];
<a name="l00500"></a>00500    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output_layer_output = forward_propagation_derivative[forward_propagation_derivative_size-2];
<a name="l00501"></a>00501 
<a name="l00502"></a>00502    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output_errors(outputs_number);
<a name="l00503"></a>00503 
<a name="l00504"></a>00504    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> error(outputs_number);
<a name="l00505"></a>00505 
<a name="l00506"></a>00506    <a class="code" href="class_flood_1_1_multilayer_perceptron.html#02c315edcb873e9bf2d95df26df13501" title="Enumeration of available methods for input variables, output variables and independent...">MultilayerPerceptron::ScalingMethod</a> outputs_unscaling_method
<a name="l00507"></a>00507    = multilayer_perceptron_pointer-&gt;get_outputs_unscaling_method();
<a name="l00508"></a>00508 
<a name="l00509"></a>00509    <span class="keywordflow">switch</span>(outputs_unscaling_method)
<a name="l00510"></a>00510    {
<a name="l00511"></a>00511       <span class="keywordflow">case</span> MultilayerPerceptron::None:
<a name="l00512"></a>00512       {   
<a name="l00513"></a>00513          error = output_layer_output-target;
<a name="l00514"></a>00514 
<a name="l00515"></a>00515          output_errors = output_layer_output_derivative*error*2.0;
<a name="l00516"></a>00516       } 
<a name="l00517"></a>00517       <span class="keywordflow">break</span>;
<a name="l00518"></a>00518 
<a name="l00519"></a>00519       <span class="keywordflow">case</span> MultilayerPerceptron::MeanStandardDeviation:
<a name="l00520"></a>00520       {         
<a name="l00521"></a>00521          <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a>&amp; output_variables_standard_deviation 
<a name="l00522"></a>00522          = multilayer_perceptron_pointer-&gt;get_output_variables_standard_deviation();
<a name="l00523"></a>00523 
<a name="l00524"></a>00524          <span class="comment">// Control sentence (if debug)</span>
<a name="l00525"></a>00525 
<a name="l00526"></a>00526 <span class="preprocessor">         #ifdef _DEBUG </span>
<a name="l00527"></a>00527 <span class="preprocessor"></span> 
<a name="l00528"></a>00528                  <span class="keywordtype">int</span> output_variables_standard_deviation_size = output_variables_standard_deviation.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00529"></a>00529 
<a name="l00530"></a>00530          <span class="keywordflow">if</span>(output_variables_standard_deviation_size != outputs_number)
<a name="l00531"></a>00531          {
<a name="l00532"></a>00532            std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00533"></a>00533                      &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00534"></a>00534                      &lt;&lt; <span class="stringliteral">"Size of output variables standard deviation must be equal to number of outputs."</span> &lt;&lt; std::endl;
<a name="l00535"></a>00535 
<a name="l00536"></a>00536            exit(1);
<a name="l00537"></a>00537          }
<a name="l00538"></a>00538 
<a name="l00539"></a>00539 <span class="preprocessor">         #endif</span>
<a name="l00540"></a>00540 <span class="preprocessor"></span>
<a name="l00541"></a>00541          output_errors = output_layer_output_derivative*error*output_variables_standard_deviation*2.0;
<a name="l00542"></a>00542       }
<a name="l00543"></a>00543       <span class="keywordflow">break</span>;
<a name="l00544"></a>00544 
<a name="l00545"></a>00545       <span class="keywordflow">case</span> MultilayerPerceptron::MinimumMaximum:
<a name="l00546"></a>00546       {
<a name="l00547"></a>00547          <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a>&amp; output_variables_minimum = multilayer_perceptron_pointer-&gt;get_output_variables_minimum();
<a name="l00548"></a>00548          <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a>&amp; output_variables_maximum = multilayer_perceptron_pointer-&gt;get_output_variables_maximum();
<a name="l00549"></a>00549 
<a name="l00550"></a>00550          <span class="comment">// Control sentence (if debug)</span>
<a name="l00551"></a>00551 
<a name="l00552"></a>00552 <span class="preprocessor">         #ifdef _DEBUG </span>
<a name="l00553"></a>00553 <span class="preprocessor"></span> 
<a name="l00554"></a>00554                  <span class="keywordtype">int</span> output_variables_minimum_size = output_variables_minimum.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00555"></a>00555                  <span class="keywordtype">int</span> output_variables_maximum_size = output_variables_maximum.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00556"></a>00556 
<a name="l00557"></a>00557          <span class="keywordflow">if</span>(output_variables_minimum_size != outputs_number)
<a name="l00558"></a>00558          {
<a name="l00559"></a>00559            std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00560"></a>00560                      &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00561"></a>00561                      &lt;&lt; <span class="stringliteral">"Size of output variables minimum must be equal to number of outputs."</span> &lt;&lt; std::endl;
<a name="l00562"></a>00562 
<a name="l00563"></a>00563            exit(1);
<a name="l00564"></a>00564          }
<a name="l00565"></a>00565          <span class="keywordflow">else</span> <span class="keywordflow">if</span>(output_variables_maximum_size != outputs_number)
<a name="l00566"></a>00566          {
<a name="l00567"></a>00567            std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00568"></a>00568                      &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00569"></a>00569                      &lt;&lt; <span class="stringliteral">"Size of output variables maximum must be equal to number of outputs."</span> &lt;&lt; std::endl;
<a name="l00570"></a>00570 
<a name="l00571"></a>00571            exit(1);
<a name="l00572"></a>00572          }
<a name="l00573"></a>00573 
<a name="l00574"></a>00574 <span class="preprocessor">         #endif</span>
<a name="l00575"></a>00575 <span class="preprocessor"></span>
<a name="l00576"></a>00576          output_errors = output_layer_output_derivative*error*(output_variables_maximum-output_variables_minimum);
<a name="l00577"></a>00577       }          
<a name="l00578"></a>00578       <span class="keywordflow">break</span>;
<a name="l00579"></a>00579       
<a name="l00580"></a>00580       <span class="keywordflow">default</span>:
<a name="l00581"></a>00581       {
<a name="l00582"></a>00582          std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00583"></a>00583                    &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00584"></a>00584                    &lt;&lt; <span class="stringliteral">"Unknown outputs unscaling method."</span> &lt;&lt; std::endl;
<a name="l00585"></a>00585 
<a name="l00586"></a>00586          exit(1);
<a name="l00587"></a>00587       }          
<a name="l00588"></a>00588       <span class="keywordflow">break</span>;
<a name="l00589"></a>00589       
<a name="l00590"></a>00590    }
<a name="l00591"></a>00591 
<a name="l00592"></a>00592    <span class="keywordflow">return</span>(output_errors);
<a name="l00593"></a>00593 }
<a name="l00594"></a>00594 
<a name="l00595"></a>00595 
<a name="l00596"></a>00596 <span class="comment">// Vector&lt; Vector&lt;double&gt; &gt; calculate_hidden_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method</span>
<a name="l00597"></a>00597 
<a name="l00601"></a>00601 
<a name="l00602"></a>00602 <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_flood_1_1_sum_squared_error.html#ead89dbd1ec4e2d8fabb546f7b4f3c1f">SumSquaredError::calculate_hidden_errors</a>
<a name="l00603"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#ead89dbd1ec4e2d8fabb546f7b4f3c1f">00603</a> (<span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; forward_propagation_derivative, <span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a>&amp; output_errors)
<a name="l00604"></a>00604 {
<a name="l00605"></a>00605    <span class="keywordtype">int</span> outputs_number = multilayer_perceptron_pointer-&gt;get_outputs_number();
<a name="l00606"></a>00606 
<a name="l00607"></a>00607    <span class="keywordtype">int</span> hidden_layers_number = multilayer_perceptron_pointer-&gt;get_hidden_layers_number();
<a name="l00608"></a>00608 
<a name="l00609"></a>00609    <span class="comment">// Control sentence (if debug)</span>
<a name="l00610"></a>00610 
<a name="l00611"></a>00611 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00612"></a>00612 <span class="preprocessor"></span>
<a name="l00613"></a>00613    <span class="keywordtype">int</span> forward_propagation_derivative_size = forward_propagation_derivative.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00614"></a>00614 
<a name="l00615"></a>00615    <span class="keywordflow">if</span>(forward_propagation_derivative_size != 2*hidden_layers_number+2)
<a name="l00616"></a>00616    {
<a name="l00617"></a>00617       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00618"></a>00618                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_hidden_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00619"></a>00619                 &lt;&lt; <span class="stringliteral">"Size of forward propagation derivative vector must be equal to 2*hidden_layers_number+2."</span> 
<a name="l00620"></a>00620                                 &lt;&lt; std::endl;
<a name="l00621"></a>00621 
<a name="l00622"></a>00622         exit(1);
<a name="l00623"></a>00623    }
<a name="l00624"></a>00624       
<a name="l00625"></a>00625    <span class="keywordtype">int</span> output_layer_output_size = forward_propagation_derivative[forward_propagation_derivative_size-2].get_size();
<a name="l00626"></a>00626       
<a name="l00627"></a>00627    <span class="keywordflow">if</span>(output_layer_output_size != outputs_number)
<a name="l00628"></a>00628    {
<a name="l00629"></a>00629       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00630"></a>00630                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_hidden_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00631"></a>00631                 &lt;&lt; <span class="stringliteral">"Size of output layer output ("</span>&lt;&lt; output_layer_output_size &lt;&lt; <span class="stringliteral">") must be equal to "</span>
<a name="l00632"></a>00632                 &lt;&lt; <span class="stringliteral">"number of outputs ("</span> &lt;&lt; outputs_number &lt;&lt; <span class="stringliteral">")."</span> &lt;&lt; std::endl;
<a name="l00633"></a>00633 
<a name="l00634"></a>00634       exit(1);
<a name="l00635"></a>00635    }
<a name="l00636"></a>00636 
<a name="l00637"></a>00637    <span class="keywordtype">int</span> output_layer_output_derivative_size 
<a name="l00638"></a>00638    = forward_propagation_derivative[forward_propagation_derivative_size-1].get_size();
<a name="l00639"></a>00639 
<a name="l00640"></a>00640    <span class="keywordflow">if</span>(output_layer_output_derivative_size != outputs_number)
<a name="l00641"></a>00641    {
<a name="l00642"></a>00642       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00643"></a>00643                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_hidden_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00644"></a>00644                 &lt;&lt; <span class="stringliteral">"Size of output layer output derivative ("</span> &lt;&lt; output_layer_output_derivative_size &lt;&lt; <span class="stringliteral">")must be equal to "</span> 
<a name="l00645"></a>00645                                 &lt;&lt; <span class="stringliteral">"number of outputs ("</span> &lt;&lt; outputs_number &lt;&lt; <span class="stringliteral">")."</span> &lt;&lt; std::endl;
<a name="l00646"></a>00646 
<a name="l00647"></a>00647       exit(1);
<a name="l00648"></a>00648    }
<a name="l00649"></a>00649 
<a name="l00650"></a>00650    <span class="keywordtype">int</span> output_errors_size = output_errors.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00651"></a>00651 
<a name="l00652"></a>00652    <span class="keywordflow">if</span>(output_errors_size != outputs_number)
<a name="l00653"></a>00653    {
<a name="l00654"></a>00654       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00655"></a>00655                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_hidden_errors(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00656"></a>00656                 &lt;&lt; <span class="stringliteral">"Size of target must be equal to number of outputs."</span> &lt;&lt; std::endl;
<a name="l00657"></a>00657 
<a name="l00658"></a>00658       exit(1);
<a name="l00659"></a>00659    }
<a name="l00660"></a>00660 
<a name="l00661"></a>00661 <span class="preprocessor">   #endif</span>
<a name="l00662"></a>00662 <span class="preprocessor"></span>
<a name="l00663"></a>00663    <span class="comment">// Set hidden errors vector of vectors</span>
<a name="l00664"></a>00664 
<a name="l00665"></a>00665    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;int&gt;</a> hidden_layers_size = multilayer_perceptron_pointer-&gt;get_hidden_layers_size();
<a name="l00666"></a>00666 
<a name="l00667"></a>00667    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; hidden_errors(hidden_layers_number);
<a name="l00668"></a>00668 
<a name="l00669"></a>00669    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = 0; h &lt; hidden_layers_number; h++)
<a name="l00670"></a>00670    {
<a name="l00671"></a>00671       hidden_errors[h].<a class="code" href="class_flood_1_1_vector.html#68039fc58f09f77466d22c5f2c131b02">set_size</a>(hidden_layers_size[h]);
<a name="l00672"></a>00672    }
<a name="l00673"></a>00673 
<a name="l00674"></a>00674    <span class="comment">// Multilayer perceptron</span>
<a name="l00675"></a>00675 
<a name="l00676"></a>00676    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;Perceptron&gt;</a>&amp; output_layer = multilayer_perceptron_pointer-&gt;get_output_layer();
<a name="l00677"></a>00677    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;Perceptron&gt;</a> &gt;&amp; hidden_layers = multilayer_perceptron_pointer-&gt;get_hidden_layers();
<a name="l00678"></a>00678 
<a name="l00679"></a>00679    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; hidden_layers_output_derivative(hidden_layers_number);
<a name="l00680"></a>00680 
<a name="l00681"></a>00681    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; hidden_layers_number; i++)
<a name="l00682"></a>00682    {
<a name="l00683"></a>00683       hidden_layers_output_derivative[i] = forward_propagation_derivative[1+2*i];
<a name="l00684"></a>00684    }
<a name="l00685"></a>00685 
<a name="l00686"></a>00686    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> synaptic_weights;
<a name="l00687"></a>00687 
<a name="l00688"></a>00688    <span class="keywordtype">double</span> sum;
<a name="l00689"></a>00689     
<a name="l00690"></a>00690    <span class="comment">// Last hidden layer</span>
<a name="l00691"></a>00691 
<a name="l00692"></a>00692    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; hidden_layers_size[hidden_layers_number-1]; j++)
<a name="l00693"></a>00693    {
<a name="l00694"></a>00694       sum = 0.0;
<a name="l00695"></a>00695 
<a name="l00696"></a>00696       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; outputs_number; k++)
<a name="l00697"></a>00697       {
<a name="l00698"></a>00698          synaptic_weights = output_layer[k].get_synaptic_weights();
<a name="l00699"></a>00699 
<a name="l00700"></a>00700          sum += (synaptic_weights[j])*output_errors[k];
<a name="l00701"></a>00701       }
<a name="l00702"></a>00702 
<a name="l00703"></a>00703       hidden_errors[hidden_layers_number-1][j] = hidden_layers_output_derivative[hidden_layers_number-1][j]*sum;
<a name="l00704"></a>00704    }
<a name="l00705"></a>00705 
<a name="l00706"></a>00706    <span class="comment">// Rest of hidden layers</span>
<a name="l00707"></a>00707 
<a name="l00708"></a>00708    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = hidden_layers_number-2; h &gt;= 0; h--) 
<a name="l00709"></a>00709    {   
<a name="l00710"></a>00710       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; hidden_layers_size[h]; j++)
<a name="l00711"></a>00711       {
<a name="l00712"></a>00712          sum = 0.0;
<a name="l00713"></a>00713 
<a name="l00714"></a>00714          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; hidden_layers_size[h+1]; k++)
<a name="l00715"></a>00715          {
<a name="l00716"></a>00716             synaptic_weights = hidden_layers[h+1][k].get_synaptic_weights();
<a name="l00717"></a>00717 
<a name="l00718"></a>00718             sum += (synaptic_weights[j])*hidden_errors[h+1][k];
<a name="l00719"></a>00719          }               
<a name="l00720"></a>00720 
<a name="l00721"></a>00721          hidden_errors[h][j] = hidden_layers_output_derivative[h][j]*sum;
<a name="l00722"></a>00722       }
<a name="l00723"></a>00723    }
<a name="l00724"></a>00724 
<a name="l00725"></a>00725    <span class="keywordflow">return</span>(hidden_errors);
<a name="l00726"></a>00726 }
<a name="l00727"></a>00727 
<a name="l00728"></a>00728 
<a name="l00729"></a>00729 <span class="comment">// Vector&lt;double&gt; calculate_hidden_layers_error_gradient</span>
<a name="l00730"></a>00730 <span class="comment">// (const Vector&lt;double&gt;&amp;, const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt; Vector&lt;double&gt; &gt;&amp;) ) method</span>
<a name="l00731"></a>00731 
<a name="l00736"></a>00736 
<a name="l00737"></a>00737 <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#0377f1256a757d4fe942a13313c7decf">SumSquaredError::calculate_hidden_layers_error_gradient</a>
<a name="l00738"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#0377f1256a757d4fe942a13313c7decf">00738</a> (<span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a>&amp; input, 
<a name="l00739"></a>00739  <span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; forward_propagation_derivative, 
<a name="l00740"></a>00740  <span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; hidden_errors)
<a name="l00741"></a>00741 {
<a name="l00742"></a>00742    <span class="keywordtype">int</span> inputs_number = multilayer_perceptron_pointer-&gt;get_inputs_number();
<a name="l00743"></a>00743    <span class="keywordtype">int</span> hidden_layers_number = multilayer_perceptron_pointer-&gt;get_hidden_layers_number();
<a name="l00744"></a>00744 
<a name="l00745"></a>00745    <span class="comment">// Control sentence (if debug)</span>
<a name="l00746"></a>00746 
<a name="l00747"></a>00747 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00748"></a>00748 <span class="preprocessor"></span>
<a name="l00749"></a>00749    <span class="keywordtype">int</span> input_size = input.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00750"></a>00750 
<a name="l00751"></a>00751    <span class="keywordflow">if</span>(input_size != inputs_number)
<a name="l00752"></a>00752    {
<a name="l00753"></a>00753       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00754"></a>00754                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_hidden_layers_error_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00755"></a>00755                 &lt;&lt; <span class="stringliteral">"Size of input ("</span> &lt;&lt; input_size &lt;&lt; <span class="stringliteral">") must be equal to inputs number ("</span> &lt;&lt; inputs_number &lt;&lt; <span class="stringliteral">")."</span> 
<a name="l00756"></a>00756                                 &lt;&lt; std::endl;
<a name="l00757"></a>00757 
<a name="l00758"></a>00758         exit(1);
<a name="l00759"></a>00759    }
<a name="l00760"></a>00760 
<a name="l00761"></a>00761 
<a name="l00762"></a>00762    <span class="keywordtype">int</span> forward_propagation_derivative_size = forward_propagation_derivative.get_size();
<a name="l00763"></a>00763 
<a name="l00764"></a>00764    <span class="keywordflow">if</span>(forward_propagation_derivative_size != 2*hidden_layers_number+2)
<a name="l00765"></a>00765    {
<a name="l00766"></a>00766       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00767"></a>00767                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_hidden_layers_error_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00768"></a>00768                 &lt;&lt; <span class="stringliteral">"Size of forward propagation derivative ("</span> &lt;&lt; forward_propagation_derivative_size &lt;&lt; <span class="stringliteral">") must be equal to 2*hidden_layers_number+2 ("</span> &lt;&lt; 2*hidden_layers_number+2 &lt;&lt; <span class="stringliteral">")."</span> 
<a name="l00769"></a>00769                                 &lt;&lt; std::endl;
<a name="l00770"></a>00770 
<a name="l00771"></a>00771         exit(1);
<a name="l00772"></a>00772    }
<a name="l00773"></a>00773       
<a name="l00774"></a>00774    <span class="keywordtype">int</span> hidden_errors_size = hidden_errors.get_size();
<a name="l00775"></a>00775       
<a name="l00776"></a>00776    <span class="keywordflow">if</span>(hidden_errors_size != hidden_layers_number)
<a name="l00777"></a>00777    {
<a name="l00778"></a>00778       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00779"></a>00779                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_hidden_layers_error_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00780"></a>00780                 &lt;&lt; <span class="stringliteral">"Size of output errors ("</span>&lt;&lt; hidden_errors_size &lt;&lt; <span class="stringliteral">") must be equal to number of hidden layers ("</span> &lt;&lt; hidden_layers_number &lt;&lt; <span class="stringliteral">")."</span> &lt;&lt; std::endl;
<a name="l00781"></a>00781 
<a name="l00782"></a>00782       exit(1);
<a name="l00783"></a>00783    }
<a name="l00784"></a>00784 
<a name="l00785"></a>00785 <span class="preprocessor">   #endif</span>
<a name="l00786"></a>00786 <span class="preprocessor"></span>
<a name="l00787"></a>00787    <span class="comment">// Multilayer perceptron stuff </span>
<a name="l00788"></a>00788 
<a name="l00789"></a>00789    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;int&gt;</a> hidden_layers_size = multilayer_perceptron_pointer-&gt;get_hidden_layers_size();
<a name="l00790"></a>00790 
<a name="l00791"></a>00791    <span class="keywordtype">int</span> hidden_layers_parameters_number = multilayer_perceptron_pointer-&gt;get_hidden_layers_parameters_number();
<a name="l00792"></a>00792 
<a name="l00793"></a>00793    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;Perceptron&gt;</a> &gt;&amp; hidden_layers = multilayer_perceptron_pointer-&gt;get_hidden_layers();
<a name="l00794"></a>00794 
<a name="l00795"></a>00795    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> synaptic_weights;
<a name="l00796"></a>00796 
<a name="l00797"></a>00797    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; hidden_layers_output(hidden_layers_number);
<a name="l00798"></a>00798 
<a name="l00799"></a>00799    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; hidden_layers_number; i++)
<a name="l00800"></a>00800    {
<a name="l00801"></a>00801       hidden_layers_output[i] = forward_propagation_derivative[2*i];
<a name="l00802"></a>00802    }
<a name="l00803"></a>00803 
<a name="l00804"></a>00804    <span class="keywordtype">int</span> index = 0;
<a name="l00805"></a>00805 
<a name="l00806"></a>00806    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> hidden_layers_error_gradient(hidden_layers_parameters_number, 0.0);
<a name="l00807"></a>00807 
<a name="l00808"></a>00808    <span class="comment">// First hidden layer</span>
<a name="l00809"></a>00809 
<a name="l00810"></a>00810    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; hidden_layers_size[0]; j++)
<a name="l00811"></a>00811    {
<a name="l00812"></a>00812       <span class="comment">// Bias</span>
<a name="l00813"></a>00813 
<a name="l00814"></a>00814       hidden_layers_error_gradient[index] += hidden_errors[0][j];
<a name="l00815"></a>00815       index++;
<a name="l00816"></a>00816 
<a name="l00817"></a>00817       <span class="comment">// Synaptic weights</span>
<a name="l00818"></a>00818 
<a name="l00819"></a>00819       synaptic_weights = hidden_layers[0][j].get_synaptic_weights();
<a name="l00820"></a>00820 
<a name="l00821"></a>00821       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; inputs_number; k++)
<a name="l00822"></a>00822       {
<a name="l00823"></a>00823          hidden_layers_error_gradient[index] += hidden_errors[0][j]*input[k];
<a name="l00824"></a>00824          index++;   
<a name="l00825"></a>00825       }
<a name="l00826"></a>00826    }
<a name="l00827"></a>00827 
<a name="l00828"></a>00828    <span class="comment">// Rest of hidden layers     </span>
<a name="l00829"></a>00829     
<a name="l00830"></a>00830    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = 1; h &lt; hidden_layers_number; h++)
<a name="l00831"></a>00831    {      
<a name="l00832"></a>00832       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; hidden_layers_size[h]; j++)
<a name="l00833"></a>00833       {
<a name="l00834"></a>00834          <span class="comment">// Bias</span>
<a name="l00835"></a>00835 
<a name="l00836"></a>00836          hidden_layers_error_gradient[index] += hidden_errors[h][j];
<a name="l00837"></a>00837          index++;
<a name="l00838"></a>00838 
<a name="l00839"></a>00839          <span class="comment">// Synaptic weights</span>
<a name="l00840"></a>00840 
<a name="l00841"></a>00841          synaptic_weights = hidden_layers[h][j].get_synaptic_weights();
<a name="l00842"></a>00842 
<a name="l00843"></a>00843          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; hidden_layers_size[h-1]; k++)
<a name="l00844"></a>00844          {
<a name="l00845"></a>00845             hidden_layers_error_gradient[index] += hidden_errors[h][j]*hidden_layers_output[h-1][k];
<a name="l00846"></a>00846             index++;   
<a name="l00847"></a>00847          }
<a name="l00848"></a>00848       }
<a name="l00849"></a>00849    }
<a name="l00850"></a>00850 
<a name="l00851"></a>00851    <span class="keywordflow">return</span>(hidden_layers_error_gradient);
<a name="l00852"></a>00852 }
<a name="l00853"></a>00853 
<a name="l00854"></a>00854 
<a name="l00855"></a>00855 <span class="comment">// Vector&lt;double&gt; calculate_output_layer_error_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method</span>
<a name="l00856"></a>00856 
<a name="l00860"></a>00860 
<a name="l00861"></a>00861 <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#2785b64fbe0829fe69c263fbf958ffcd">SumSquaredError::calculate_output_layer_error_gradient</a>
<a name="l00862"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#2785b64fbe0829fe69c263fbf958ffcd">00862</a> (<span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; forward_propagation_derivative, <span class="keyword">const</span> <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a>&amp; output_errors)
<a name="l00863"></a>00863 {
<a name="l00864"></a>00864    <span class="keywordtype">int</span> outputs_number = multilayer_perceptron_pointer-&gt;get_outputs_number();
<a name="l00865"></a>00865    <span class="keywordtype">int</span> hidden_layers_number = multilayer_perceptron_pointer-&gt;get_hidden_layers_number();
<a name="l00866"></a>00866 
<a name="l00867"></a>00867    <span class="comment">// Control sentence (if debug)</span>
<a name="l00868"></a>00868 
<a name="l00869"></a>00869 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00870"></a>00870 <span class="preprocessor"></span>
<a name="l00871"></a>00871    <span class="keywordtype">int</span> forward_propagation_derivative_size = forward_propagation_derivative.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00872"></a>00872 
<a name="l00873"></a>00873    <span class="keywordflow">if</span>(forward_propagation_derivative_size != 2*hidden_layers_number+2)
<a name="l00874"></a>00874    {
<a name="l00875"></a>00875       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00876"></a>00876                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_output_layer_error_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00877"></a>00877                 &lt;&lt; <span class="stringliteral">"Size of forward propagation derivative ("</span> &lt;&lt; forward_propagation_derivative_size &lt;&lt; <span class="stringliteral">") must be equal to 2*hidden_layers_number+2 ("</span> &lt;&lt; 2*hidden_layers_number+2 &lt;&lt; <span class="stringliteral">")."</span> &lt;&lt; std::endl;
<a name="l00878"></a>00878 
<a name="l00879"></a>00879         exit(1);
<a name="l00880"></a>00880    }
<a name="l00881"></a>00881       
<a name="l00882"></a>00882    <span class="keywordtype">int</span> output_errors_size = output_errors.<a class="code" href="class_flood_1_1_vector.html#3bbdc306ef2ee1922c966f0a2925328c" title="This method returns the number of elements in the vector.">get_size</a>();
<a name="l00883"></a>00883       
<a name="l00884"></a>00884    <span class="keywordflow">if</span>(output_errors_size != outputs_number)
<a name="l00885"></a>00885    {
<a name="l00886"></a>00886       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00887"></a>00887                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_output_layer_error_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method."</span> &lt;&lt; std::endl
<a name="l00888"></a>00888                 &lt;&lt; <span class="stringliteral">"Size of output errors ("</span>&lt;&lt; output_errors_size &lt;&lt; <span class="stringliteral">") must be equal to number of outputs ("</span> &lt;&lt; outputs_number &lt;&lt; <span class="stringliteral">")."</span> &lt;&lt; std::endl;
<a name="l00889"></a>00889 
<a name="l00890"></a>00890       exit(1);
<a name="l00891"></a>00891    }
<a name="l00892"></a>00892 
<a name="l00893"></a>00893 <span class="preprocessor">   #endif</span>
<a name="l00894"></a>00894 <span class="preprocessor"></span>
<a name="l00895"></a>00895    <span class="comment">// Multilayer perceptron stuff</span>
<a name="l00896"></a>00896 
<a name="l00897"></a>00897    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;int&gt;</a> hidden_layers_size = multilayer_perceptron_pointer-&gt;get_hidden_layers_size();
<a name="l00898"></a>00898 
<a name="l00899"></a>00899    <span class="keywordtype">int</span> output_layer_parameters_number = multilayer_perceptron_pointer-&gt;get_output_layer_parameters_number();
<a name="l00900"></a>00900 
<a name="l00901"></a>00901    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; hidden_layers_output(hidden_layers_number);
<a name="l00902"></a>00902 
<a name="l00903"></a>00903    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; hidden_layers_number; i++)
<a name="l00904"></a>00904    {
<a name="l00905"></a>00905       hidden_layers_output[i] = forward_propagation_derivative[2*i];
<a name="l00906"></a>00906    }
<a name="l00907"></a>00907 
<a name="l00908"></a>00908    <span class="comment">// Calculate gradient elements of output neurons</span>
<a name="l00909"></a>00909 
<a name="l00910"></a>00910    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output_layer_error_gradient(output_layer_parameters_number, 0.0);
<a name="l00911"></a>00911 
<a name="l00912"></a>00912    <span class="keywordtype">int</span> index = 0;
<a name="l00913"></a>00913 
<a name="l00914"></a>00914    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; outputs_number; j++)
<a name="l00915"></a>00915    {
<a name="l00916"></a>00916       <span class="comment">// Bias</span>
<a name="l00917"></a>00917 
<a name="l00918"></a>00918       output_layer_error_gradient[index] += output_errors[j];
<a name="l00919"></a>00919       index++;
<a name="l00920"></a>00920 
<a name="l00921"></a>00921       <span class="comment">// Synaptic weights</span>
<a name="l00922"></a>00922 
<a name="l00923"></a>00923       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; hidden_layers_size[hidden_layers_number-1]; k++)
<a name="l00924"></a>00924       {
<a name="l00925"></a>00925          output_layer_error_gradient[index] = hidden_layers_output[hidden_layers_number-1][k]*output_errors[j];
<a name="l00926"></a>00926          index++;
<a name="l00927"></a>00927       }
<a name="l00928"></a>00928    }
<a name="l00929"></a>00929 
<a name="l00930"></a>00930    <span class="keywordflow">return</span>(output_layer_error_gradient);
<a name="l00931"></a>00931 }
<a name="l00932"></a>00932 
<a name="l00933"></a>00933 
<a name="l00934"></a>00934 <span class="comment">// Matrix&lt;double&gt; calculate_Jacobian(void) method</span>
<a name="l00935"></a>00935 
<a name="l00939"></a>00939 
<a name="l00940"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#030fd76905d145d2d219c6007b9a80b0">00940</a> <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#030fd76905d145d2d219c6007b9a80b0">SumSquaredError::calculate_Jacobian</a>(<span class="keywordtype">void</span>)
<a name="l00941"></a>00941 {
<a name="l00942"></a>00942    <span class="comment">// Control sentence (if debug)</span>
<a name="l00943"></a>00943 
<a name="l00944"></a>00944 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00945"></a>00945 <span class="preprocessor"></span>
<a name="l00946"></a>00946    <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> == NULL)
<a name="l00947"></a>00947    {
<a name="l00948"></a>00948       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00949"></a>00949                 &lt;&lt; <span class="stringliteral">"double calculate_Jacobian(void) method."</span> &lt;&lt; std::endl
<a name="l00950"></a>00950                 &lt;&lt; <span class="stringliteral">"Pointer to multilayer perceptron object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l00951"></a>00951 
<a name="l00952"></a>00952         exit(1);
<a name="l00953"></a>00953    }
<a name="l00954"></a>00954    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(input_target_data_set_pointer == NULL)
<a name="l00955"></a>00955    {
<a name="l00956"></a>00956       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00957"></a>00957                 &lt;&lt; <span class="stringliteral">"double calculate_Jacobian(void) method."</span> &lt;&lt; std::endl
<a name="l00958"></a>00958                 &lt;&lt; <span class="stringliteral">"Pointer to input-target data set object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l00959"></a>00959 
<a name="l00960"></a>00960       exit(1);
<a name="l00961"></a>00961    }
<a name="l00962"></a>00962 
<a name="l00963"></a>00963 <span class="preprocessor">   #endif</span>
<a name="l00964"></a>00964 <span class="preprocessor"></span>
<a name="l00965"></a>00965    <span class="keywordtype">int</span> training_instances_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#57033471aae443333b57a24ebbf4910e" title="This method returns the number of instances in the data set which will be used for...">get_training_instances_number</a>();
<a name="l00966"></a>00966    <span class="keywordtype">int</span> neural_parameters_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f946d6197c1edf7d7546467fe81ea10d" title="This method returns the number neural parameters (biases and synaptic weights) in...">get_neural_parameters_number</a>();
<a name="l00967"></a>00967 
<a name="l00968"></a>00968    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> Jacobian(training_instances_number, neural_parameters_number);
<a name="l00969"></a>00969 
<a name="l00970"></a>00970    <span class="comment">// Multilayer perceptron </span>
<a name="l00971"></a>00971 
<a name="l00972"></a>00972    <span class="keywordtype">int</span> hidden_layers_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#93fca24946b4bb32aca35a2fc3c6169a" title="This method returns the number of hidden layers in the multilayer perceptron.">get_hidden_layers_number</a>();
<a name="l00973"></a>00973 
<a name="l00974"></a>00974    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;int&gt;</a> hidden_layers_size = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#fd29554ea06a09fc3a55a9aef8bab4ca" title="This method returns a vector containing the numbers of neurons in each hidden layer...">get_hidden_layers_size</a>();
<a name="l00975"></a>00975 
<a name="l00976"></a>00976    <span class="keywordtype">int</span> outputs_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#eb935150e692d7782823128c788fad9c" title="This method returns the number of neurons in the output layer of the neural network...">get_outputs_number</a>();
<a name="l00977"></a>00977 
<a name="l00978"></a>00978    <span class="keywordtype">int</span> forward_propagation_derivative_size = 2*hidden_layers_number + 2;
<a name="l00979"></a>00979 
<a name="l00980"></a>00980    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; forward_propagation_derivative(forward_propagation_derivative_size);
<a name="l00981"></a>00981 
<a name="l00982"></a>00982    <span class="comment">// Input-target data set</span>
<a name="l00983"></a>00983 
<a name="l00984"></a>00984    <span class="keywordtype">int</span> target_variables_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#7617eae51cdb86c8fefb8c5a608962ed" title="This method returns the number of target variables of the input-target data set.">get_target_variables_number</a>();    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> training_input_instance(target_variables_number);
<a name="l00985"></a>00985    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> training_target_instance(target_variables_number);
<a name="l00986"></a>00986 
<a name="l00987"></a>00987    <span class="comment">// Output and hidden errors</span>
<a name="l00988"></a>00988 
<a name="l00989"></a>00989    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output_errors(outputs_number);
<a name="l00990"></a>00990    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; hidden_errors(hidden_layers_number);
<a name="l00991"></a>00991 
<a name="l00992"></a>00992    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = 0; h &lt; hidden_layers_number; h++)
<a name="l00993"></a>00993    {
<a name="l00994"></a>00994       hidden_errors[h].<a class="code" href="class_flood_1_1_vector.html#68039fc58f09f77466d22c5f2c131b02">set_size</a>(hidden_layers_size[h]);
<a name="l00995"></a>00995    }
<a name="l00996"></a>00996 
<a name="l00997"></a>00997    <span class="comment">// Hidden and output layers gradients</span>
<a name="l00998"></a>00998 
<a name="l00999"></a>00999    <span class="keywordtype">int</span> hidden_layers_parameters_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#4ce80b9945c8629c6c5123a69f20e439" title="This method returns the number of neural parameters (biases and synaptic weights)...">get_hidden_layers_parameters_number</a>();
<a name="l01000"></a>01000    <span class="keywordtype">int</span> output_layer_parameters_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#56abb33a0ce8499a33bdf7777f2b93c1" title="This method returns the number of neural parameters (biases and synaptic weights)...">get_output_layer_parameters_number</a>();
<a name="l01001"></a>01001 
<a name="l01002"></a>01002    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> hidden_layers_error_gradient(hidden_layers_parameters_number, 0.0);
<a name="l01003"></a>01003    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output_layer_error_gradient(output_layer_parameters_number, 0.0);
<a name="l01004"></a>01004 
<a name="l01005"></a>01005    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> gradient(outputs_number);
<a name="l01006"></a>01006 
<a name="l01007"></a>01007    <span class="comment">// Main loop</span>
<a name="l01008"></a>01008 
<a name="l01009"></a>01009    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; training_instances_number; i++)
<a name="l01010"></a>01010    {
<a name="l01011"></a>01011       training_input_instance = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#51b4afaebebd097d321d3f3bed696093">get_training_input_instance</a>(i);
<a name="l01012"></a>01012 
<a name="l01013"></a>01013       forward_propagation_derivative = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#94edc7c4a12eec9b777acfee548f4782">calculate_forward_propagation_derivative</a>(training_input_instance);
<a name="l01014"></a>01014 
<a name="l01015"></a>01015       training_target_instance = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#61497ffefa06bc839723af12fd1342f1">get_training_target_instance</a>(i);
<a name="l01016"></a>01016 
<a name="l01017"></a>01017       output_errors = <a class="code" href="class_flood_1_1_sum_squared_error.html#1b89f88d8c08d06b7cb82bc883d2e110">calculate_output_errors</a>(forward_propagation_derivative, training_target_instance);
<a name="l01018"></a>01018 
<a name="l01019"></a>01019       hidden_errors = <a class="code" href="class_flood_1_1_sum_squared_error.html#ead89dbd1ec4e2d8fabb546f7b4f3c1f">calculate_hidden_errors</a>(forward_propagation_derivative, output_errors);
<a name="l01020"></a>01020 
<a name="l01021"></a>01021       hidden_layers_error_gradient = <a class="code" href="class_flood_1_1_sum_squared_error.html#0377f1256a757d4fe942a13313c7decf">calculate_hidden_layers_error_gradient</a>(training_input_instance, forward_propagation_derivative, hidden_errors);
<a name="l01022"></a>01022 
<a name="l01023"></a>01023       output_layer_error_gradient = <a class="code" href="class_flood_1_1_sum_squared_error.html#2785b64fbe0829fe69c263fbf958ffcd">calculate_output_layer_error_gradient</a>(forward_propagation_derivative, output_errors);
<a name="l01024"></a>01024 
<a name="l01025"></a>01025       gradient = hidden_layers_error_gradient.<a class="code" href="class_flood_1_1_vector.html#661629167de2ffe623c451339cb6b11c">assemble</a>(output_layer_error_gradient);
<a name="l01026"></a>01026 
<a name="l01027"></a>01027       Jacobian.<a class="code" href="class_flood_1_1_matrix.html#5ed17490798a6775d01d0f366af622d6">set_row</a>(i, gradient);
<a name="l01028"></a>01028    }
<a name="l01029"></a>01029 
<a name="l01030"></a>01030    <span class="keywordflow">return</span>(Jacobian);
<a name="l01031"></a>01031 }
<a name="l01032"></a>01032 
<a name="l01033"></a>01033 
<a name="l01034"></a>01034 <span class="comment">// Matrix&lt;double&gt; calculate_Jacobian_numerical_differentiation(void) method</span>
<a name="l01035"></a>01035 
<a name="l01038"></a>01038 
<a name="l01039"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#4faba50aae4fdb72bd364469a8826f1d">01039</a> <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#4faba50aae4fdb72bd364469a8826f1d">SumSquaredError::calculate_Jacobian_numerical_differentiation</a>(<span class="keywordtype">void</span>)
<a name="l01040"></a>01040 {
<a name="l01041"></a>01041    <span class="comment">// Control sentence (if debug)</span>
<a name="l01042"></a>01042 
<a name="l01043"></a>01043 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01044"></a>01044 <span class="preprocessor"></span>
<a name="l01045"></a>01045    <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> == NULL)
<a name="l01046"></a>01046    {
<a name="l01047"></a>01047       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l01048"></a>01048                 &lt;&lt; <span class="stringliteral">"double calculate_Jacobian_numerical_differentiation(void) method."</span> &lt;&lt; std::endl
<a name="l01049"></a>01049                 &lt;&lt; <span class="stringliteral">"Pointer to multilayer perceptron object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l01050"></a>01050 
<a name="l01051"></a>01051         exit(1);
<a name="l01052"></a>01052    }
<a name="l01053"></a>01053    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(input_target_data_set_pointer == NULL)
<a name="l01054"></a>01054    {
<a name="l01055"></a>01055       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l01056"></a>01056                 &lt;&lt; <span class="stringliteral">"double calculate_Jacobian_numerical_differentiation(void) method."</span> &lt;&lt; std::endl
<a name="l01057"></a>01057                 &lt;&lt; <span class="stringliteral">"Pointer to input-target data set object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l01058"></a>01058 
<a name="l01059"></a>01059       exit(1);
<a name="l01060"></a>01060    }
<a name="l01061"></a>01061 
<a name="l01062"></a>01062 <span class="preprocessor">   #endif</span>
<a name="l01063"></a>01063 <span class="preprocessor"></span>
<a name="l01064"></a>01064    <span class="keywordflow">switch</span>(<a class="code" href="class_flood_1_1_objective_functional.html#c4e97a0db714529528ac2c56064893e3" title="Numerical differentiation methods enumeration.">numerical_differentiation_method</a>)   
<a name="l01065"></a>01065    {
<a name="l01066"></a>01066       <span class="keywordflow">case</span> ForwardDifferences:
<a name="l01067"></a>01067       {
<a name="l01068"></a>01068          <span class="keywordflow">return</span>(<a class="code" href="class_flood_1_1_sum_squared_error.html#5dd3a4c0bfab229b6860eba688aa2503">calculate_Jacobian_forward_differences</a>());
<a name="l01069"></a>01069       }
<a name="l01070"></a>01070       <span class="keywordflow">break</span>;
<a name="l01071"></a>01071 
<a name="l01072"></a>01072       <span class="keywordflow">case</span> CentralDifferences:
<a name="l01073"></a>01073       {
<a name="l01074"></a>01074          <span class="keywordflow">return</span>(<a class="code" href="class_flood_1_1_sum_squared_error.html#d1f3955e8bafe01f28c43625d47036a7">calculate_Jacobian_central_differences</a>());
<a name="l01075"></a>01075       }
<a name="l01076"></a>01076       <span class="keywordflow">break</span>;
<a name="l01077"></a>01077 
<a name="l01078"></a>01078       <span class="keywordflow">default</span>:
<a name="l01079"></a>01079       {
<a name="l01080"></a>01080          std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l01081"></a>01081                    &lt;&lt; <span class="stringliteral">"std::string calculate_Jacobian_numerical_differentiation(void) method."</span> &lt;&lt; std::endl
<a name="l01082"></a>01082                    &lt;&lt; <span class="stringliteral">"Unknown numerical differentiation method."</span> &lt;&lt; std::endl;
<a name="l01083"></a>01083  
<a name="l01084"></a>01084          exit(1);
<a name="l01085"></a>01085       }
<a name="l01086"></a>01086       <span class="keywordflow">break</span>;
<a name="l01087"></a>01087    }
<a name="l01088"></a>01088 }
<a name="l01089"></a>01089 
<a name="l01090"></a>01090 
<a name="l01091"></a>01091 <span class="comment">// Matrix&lt;double&gt; calculate_Jacobian_forward_differences(void) method</span>
<a name="l01092"></a>01092 
<a name="l01095"></a>01095 
<a name="l01096"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#5dd3a4c0bfab229b6860eba688aa2503">01096</a> <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#5dd3a4c0bfab229b6860eba688aa2503">SumSquaredError::calculate_Jacobian_forward_differences</a>(<span class="keywordtype">void</span>)
<a name="l01097"></a>01097 {
<a name="l01098"></a>01098    <span class="keywordtype">int</span> training_instances_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#57033471aae443333b57a24ebbf4910e" title="This method returns the number of instances in the data set which will be used for...">get_training_instances_number</a>();
<a name="l01099"></a>01099    <span class="keywordtype">int</span> neural_parameters_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f946d6197c1edf7d7546467fe81ea10d" title="This method returns the number neural parameters (biases and synaptic weights) in...">get_neural_parameters_number</a>();
<a name="l01100"></a>01100 
<a name="l01101"></a>01101    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> Jacobian(training_instances_number, neural_parameters_number);
<a name="l01102"></a>01102 
<a name="l01103"></a>01103    <span class="comment">// Multilayer perceptron stuff</span>
<a name="l01104"></a>01104 
<a name="l01105"></a>01105    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> neural_parameters = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#ae7c1c974a2d96c29a9143b8b705002e" title="This method returns the values of all the biases and synaptic weights in the neural...">get_neural_parameters</a>();
<a name="l01106"></a>01106 
<a name="l01107"></a>01107    <span class="comment">// Objective functional stuff</span>
<a name="l01108"></a>01108 
<a name="l01109"></a>01109    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squared_errors = <a class="code" href="class_flood_1_1_sum_squared_error.html#2d860b178aa9d18a8b5f979004917bc6" title="This method returns the squared errors of the training instances.">calculate_squared_errors</a>(); 
<a name="l01110"></a>01110 
<a name="l01111"></a>01111    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squared_errors_forward(training_instances_number);
<a name="l01112"></a>01112 
<a name="l01113"></a>01113    <span class="keywordtype">double</span> actual_epsilon;
<a name="l01114"></a>01114 
<a name="l01115"></a>01115    <span class="comment">// Calculate Jacobian</span>
<a name="l01116"></a>01116 
<a name="l01117"></a>01117    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; neural_parameters_number; j++)
<a name="l01118"></a>01118    {
<a name="l01119"></a>01119       actual_epsilon = <a class="code" href="class_flood_1_1_objective_functional.html#0579530e989b57becc9ee71e10e17f4f">calculate_actual_epsilon</a>(neural_parameters[j]);
<a name="l01120"></a>01120 
<a name="l01121"></a>01121       <span class="comment">// Perturbate neural parameters</span>
<a name="l01122"></a>01122 
<a name="l01123"></a>01123       neural_parameters[j] += actual_epsilon;
<a name="l01124"></a>01124       <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d325c0d171a63a726e490c8a37843930">set_neural_parameters</a>(neural_parameters);
<a name="l01125"></a>01125 
<a name="l01126"></a>01126       <span class="comment">// Calculate squared errors forward</span>
<a name="l01127"></a>01127 
<a name="l01128"></a>01128       squared_errors_forward = <a class="code" href="class_flood_1_1_sum_squared_error.html#2d860b178aa9d18a8b5f979004917bc6" title="This method returns the squared errors of the training instances.">calculate_squared_errors</a>();
<a name="l01129"></a>01129 
<a name="l01130"></a>01130       <span class="comment">// Restart biases and synaptic weights</span>
<a name="l01131"></a>01131 
<a name="l01132"></a>01132       neural_parameters[j] -= actual_epsilon;
<a name="l01133"></a>01133       <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d325c0d171a63a726e490c8a37843930">set_neural_parameters</a>(neural_parameters);
<a name="l01134"></a>01134 
<a name="l01135"></a>01135       <span class="comment">// Calculate Jacobian elements</span>
<a name="l01136"></a>01136                         
<a name="l01137"></a>01137       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; training_instances_number; i++)
<a name="l01138"></a>01138       {
<a name="l01139"></a>01139          Jacobian[i][j] = (squared_errors_forward[i] - squared_errors[i])/actual_epsilon;
<a name="l01140"></a>01140       }
<a name="l01141"></a>01141    }
<a name="l01142"></a>01142 
<a name="l01143"></a>01143    <span class="keywordflow">return</span>(Jacobian);
<a name="l01144"></a>01144 }
<a name="l01145"></a>01145 
<a name="l01146"></a>01146 
<a name="l01147"></a>01147 <span class="comment">// Matrix&lt;double&gt; calculate_Jacobian_central_differences(void) method</span>
<a name="l01148"></a>01148 
<a name="l01151"></a>01151 
<a name="l01152"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#d1f3955e8bafe01f28c43625d47036a7">01152</a> <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#d1f3955e8bafe01f28c43625d47036a7">SumSquaredError::calculate_Jacobian_central_differences</a>(<span class="keywordtype">void</span>)
<a name="l01153"></a>01153 {
<a name="l01154"></a>01154    <span class="keywordtype">int</span> training_instances_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#57033471aae443333b57a24ebbf4910e" title="This method returns the number of instances in the data set which will be used for...">get_training_instances_number</a>();
<a name="l01155"></a>01155    <span class="keywordtype">int</span> neural_parameters_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f946d6197c1edf7d7546467fe81ea10d" title="This method returns the number neural parameters (biases and synaptic weights) in...">get_neural_parameters_number</a>();
<a name="l01156"></a>01156 
<a name="l01157"></a>01157    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> Jacobian(training_instances_number, neural_parameters_number);
<a name="l01158"></a>01158 
<a name="l01159"></a>01159    <span class="comment">// Multilayer perceptron stuff</span>
<a name="l01160"></a>01160 
<a name="l01161"></a>01161    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> neural_parameters = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#ae7c1c974a2d96c29a9143b8b705002e" title="This method returns the values of all the biases and synaptic weights in the neural...">get_neural_parameters</a>();
<a name="l01162"></a>01162 
<a name="l01163"></a>01163    <span class="comment">// Objective functional stuff</span>
<a name="l01164"></a>01164    
<a name="l01165"></a>01165    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squared_errors_forward(training_instances_number);
<a name="l01166"></a>01166    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squared_errors_backward(training_instances_number);
<a name="l01167"></a>01167 
<a name="l01168"></a>01168    <span class="keywordtype">double</span> actual_epsilon;
<a name="l01169"></a>01169 
<a name="l01170"></a>01170    <span class="comment">// Calculate Jacobian</span>
<a name="l01171"></a>01171 
<a name="l01172"></a>01172    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; neural_parameters_number; j++)
<a name="l01173"></a>01173    {
<a name="l01174"></a>01174       actual_epsilon = <a class="code" href="class_flood_1_1_objective_functional.html#0579530e989b57becc9ee71e10e17f4f">calculate_actual_epsilon</a>(neural_parameters[j]);
<a name="l01175"></a>01175       
<a name="l01176"></a>01176       <span class="comment">// Perturbate neural parameters</span>
<a name="l01177"></a>01177 
<a name="l01178"></a>01178       neural_parameters[j] += actual_epsilon;
<a name="l01179"></a>01179       <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d325c0d171a63a726e490c8a37843930">set_neural_parameters</a>(neural_parameters);
<a name="l01180"></a>01180 
<a name="l01181"></a>01181       <span class="comment">// Calculate squared errors     </span>
<a name="l01182"></a>01182  
<a name="l01183"></a>01183       squared_errors_forward = <a class="code" href="class_flood_1_1_sum_squared_error.html#2d860b178aa9d18a8b5f979004917bc6" title="This method returns the squared errors of the training instances.">calculate_squared_errors</a>();
<a name="l01184"></a>01184  
<a name="l01185"></a>01185       <span class="comment">// Restart neural parameters</span>
<a name="l01186"></a>01186 
<a name="l01187"></a>01187       neural_parameters[j] -= actual_epsilon;
<a name="l01188"></a>01188       <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d325c0d171a63a726e490c8a37843930">set_neural_parameters</a>(neural_parameters);
<a name="l01189"></a>01189 
<a name="l01190"></a>01190       <span class="comment">// Perturbate neural parameters</span>
<a name="l01191"></a>01191 
<a name="l01192"></a>01192       neural_parameters[j] -= actual_epsilon;
<a name="l01193"></a>01193       <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d325c0d171a63a726e490c8a37843930">set_neural_parameters</a>(neural_parameters);
<a name="l01194"></a>01194 
<a name="l01195"></a>01195       <span class="comment">// Calculate squared errors     </span>
<a name="l01196"></a>01196  
<a name="l01197"></a>01197       squared_errors_backward = <a class="code" href="class_flood_1_1_sum_squared_error.html#2d860b178aa9d18a8b5f979004917bc6" title="This method returns the squared errors of the training instances.">calculate_squared_errors</a>();
<a name="l01198"></a>01198  
<a name="l01199"></a>01199       <span class="comment">// Restart neural parameters</span>
<a name="l01200"></a>01200 
<a name="l01201"></a>01201       neural_parameters[j] += actual_epsilon;
<a name="l01202"></a>01202       <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d325c0d171a63a726e490c8a37843930">set_neural_parameters</a>(neural_parameters);
<a name="l01203"></a>01203 
<a name="l01204"></a>01204       <span class="comment">// Calculate Jacobian elements</span>
<a name="l01205"></a>01205 
<a name="l01206"></a>01206       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; training_instances_number; i++)
<a name="l01207"></a>01207       {
<a name="l01208"></a>01208          Jacobian[i][j] = (squared_errors_forward[i] - squared_errors_backward[i])/(2.0*actual_epsilon);
<a name="l01209"></a>01209       }
<a name="l01210"></a>01210    }
<a name="l01211"></a>01211 
<a name="l01212"></a>01212    <span class="keywordflow">return</span>(Jacobian);
<a name="l01213"></a>01213 }
<a name="l01214"></a>01214 
<a name="l01215"></a>01215 
<a name="l01216"></a>01216 <span class="comment">// Vector&lt;double&gt; calculate_squared_errors(void) method</span>
<a name="l01217"></a>01217 
<a name="l01219"></a>01219 
<a name="l01220"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#2d860b178aa9d18a8b5f979004917bc6">01220</a> <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#2d860b178aa9d18a8b5f979004917bc6" title="This method returns the squared errors of the training instances.">SumSquaredError::calculate_squared_errors</a>(<span class="keywordtype">void</span>)
<a name="l01221"></a>01221 {
<a name="l01222"></a>01222    <span class="comment">// Control sentence (if debug)</span>
<a name="l01223"></a>01223 
<a name="l01224"></a>01224 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01225"></a>01225 <span class="preprocessor"></span>
<a name="l01226"></a>01226    <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a> == NULL)
<a name="l01227"></a>01227    {
<a name="l01228"></a>01228       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l01229"></a>01229                 &lt;&lt; <span class="stringliteral">"double calculate_Jacobian_numerical_differentiation(void) method."</span> &lt;&lt; std::endl
<a name="l01230"></a>01230                 &lt;&lt; <span class="stringliteral">"Pointer to multilayer perceptron object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l01231"></a>01231 
<a name="l01232"></a>01232         exit(1);
<a name="l01233"></a>01233    }
<a name="l01234"></a>01234    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(input_target_data_set_pointer == NULL)
<a name="l01235"></a>01235    {
<a name="l01236"></a>01236       std::cerr &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l01237"></a>01237                 &lt;&lt; <span class="stringliteral">"double calculate_Jacobian_numerical_differentiation(void) method."</span> &lt;&lt; std::endl
<a name="l01238"></a>01238                 &lt;&lt; <span class="stringliteral">"Pointer to input-target data set object cannot be NULL."</span> &lt;&lt; std::endl;
<a name="l01239"></a>01239 
<a name="l01240"></a>01240       exit(1);
<a name="l01241"></a>01241    }
<a name="l01242"></a>01242 
<a name="l01243"></a>01243 <span class="preprocessor">   #endif</span>
<a name="l01244"></a>01244 <span class="preprocessor"></span>
<a name="l01245"></a>01245    <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f6eca87cfe21b50fe1018152fa696788" title="This method returns the number of inputs in the neural network.">get_inputs_number</a>();
<a name="l01246"></a>01246    <span class="keywordtype">int</span> outputs_number = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#eb935150e692d7782823128c788fad9c" title="This method returns the number of neurons in the output layer of the neural network...">get_outputs_number</a>();
<a name="l01247"></a>01247 
<a name="l01248"></a>01248    <span class="keywordtype">int</span> training_instances_number = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#57033471aae443333b57a24ebbf4910e" title="This method returns the number of instances in the data set which will be used for...">get_training_instances_number</a>();
<a name="l01249"></a>01249 
<a name="l01250"></a>01250    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squared_errors(training_instances_number);
<a name="l01251"></a>01251 
<a name="l01252"></a>01252    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> input(inputs_number);
<a name="l01253"></a>01253    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output(outputs_number);
<a name="l01254"></a>01254    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> target(outputs_number);
<a name="l01255"></a>01255    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> instance_error(outputs_number);
<a name="l01256"></a>01256 
<a name="l01257"></a>01257    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; training_instances_number; i++)
<a name="l01258"></a>01258    {
<a name="l01259"></a>01259       <span class="comment">// Input vector</span>
<a name="l01260"></a>01260 
<a name="l01261"></a>01261           input = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#51b4afaebebd097d321d3f3bed696093">get_training_input_instance</a>(i);
<a name="l01262"></a>01262 
<a name="l01263"></a>01263       <span class="comment">// Output vector</span>
<a name="l01264"></a>01264 
<a name="l01265"></a>01265       output = <a class="code" href="class_flood_1_1_objective_functional.html#254f1621611a944e8e4ef022b2be85f1" title="Pointer to a multilayer perceptron object.">multilayer_perceptron_pointer</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#174c73e190ed9f64f4e56cb697f8cdd8">calculate_output</a>(input);
<a name="l01266"></a>01266 
<a name="l01267"></a>01267       <span class="comment">// Target vector</span>
<a name="l01268"></a>01268 
<a name="l01269"></a>01269       target = input_target_data_set_pointer-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#61497ffefa06bc839723af12fd1342f1">get_training_target_instance</a>(i);
<a name="l01270"></a>01270 
<a name="l01271"></a>01271       <span class="comment">// Error</span>
<a name="l01272"></a>01272 
<a name="l01273"></a>01273           squared_errors[i] = (output - target).dot(output - target);
<a name="l01274"></a>01274    }
<a name="l01275"></a>01275 
<a name="l01276"></a>01276    <span class="keywordflow">return</span>(squared_errors);
<a name="l01277"></a>01277 }
<a name="l01278"></a>01278 
<a name="l01279"></a>01279 }
<a name="l01280"></a>01280 
<a name="l01281"></a>01281 <span class="comment">// Flood: An Open Source Neural Networks C++ Library.</span>
<a name="l01282"></a>01282 <span class="comment">// Copyright (C) 2005-2010 Roberto Lopez </span>
<a name="l01283"></a>01283 <span class="comment">//</span>
<a name="l01284"></a>01284 <span class="comment">// This library is free software; you can redistribute it and/or</span>
<a name="l01285"></a>01285 <span class="comment">// modify it under the s of the GNU Lesser General Public</span>
<a name="l01286"></a>01286 <span class="comment">// License as published by the Free Software Foundation; either</span>
<a name="l01287"></a>01287 <span class="comment">// version 2.1 of the License, or any later version.</span>
<a name="l01288"></a>01288 <span class="comment">//</span>
<a name="l01289"></a>01289 <span class="comment">// This library is distributed in the hope that it will be useful,</span>
<a name="l01290"></a>01290 <span class="comment">// but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<a name="l01291"></a>01291 <span class="comment">// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU</span>
<a name="l01292"></a>01292 <span class="comment">// Lesser General Public License for more details.</span>
<a name="l01293"></a>01293 <span class="comment">// You should have received a copy of the GNU Lesser General Public</span>
<a name="l01294"></a>01294 <span class="comment">// License along with this library; if not, write to the Free Software</span>
<a name="l01295"></a>01295 <span class="comment">// Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA</span>
<a name="l01296"></a>01296 
</pre></div></div>
<hr size="1"><address style="text-align: right;"><small>Generated on Fri Jul 30 09:51:50 2010 for Flood by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.9 </small></address>
</body>
</html>
